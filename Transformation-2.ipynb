{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ac4063e",
   "metadata": {},
   "source": [
    "# Smoothing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3642e6e",
   "metadata": {},
   "source": [
    "## 2D Convolution (Image Filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a5913a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"img/actress.jpg\")\n",
    "\n",
    "kernel = np.ones((5,5),np.float32)/25\n",
    "dst = cv2.filter2D(img,-1,kernel)\n",
    "\n",
    "cv2.imshow(\"Conv2D\",dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5726c5e3",
   "metadata": {},
   "source": [
    "## Image Blurring (Image Smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8c0c05",
   "metadata": {},
   "source": [
    "### Aveeraging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1104d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('img/actress.jpg')\n",
    "\n",
    "blur = cv2.blur(img,(5,5))\n",
    "cv2.imshow(\"BLUR\",blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a263f5",
   "metadata": {},
   "source": [
    "### Gaussian Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5f04ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('img/actress.jpg')\n",
    "\n",
    "blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "cv2.imshow('Gaussian Filtering', blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d283fd3e",
   "metadata": {},
   "source": [
    "### Median Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277727fe",
   "metadata": {},
   "source": [
    "he function cv2.medianBlur() computes the median of all the pixels under the kernel window and the central pixel is replaced with this median value.\n",
    "\n",
    "This is highly effective in removing salt-and-pepper noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f315389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('img/actress.jpg')\n",
    "\n",
    "median = cv2.medianBlur(img,5)\n",
    "cv2.imshow('Median Filtering', blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99e8f37",
   "metadata": {},
   "source": [
    "# Morphological Transformations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0348765",
   "metadata": {},
   "source": [
    "Morphological transformations are some simple operations based on the image shape. It is normally performed on binary images. It needs two inputs, one is our original image, second one is called structuring element or kernel which decides the nature of operation.\n",
    "\n",
    "Two basic morphological operators are Erosion and Dilation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2facd4f5",
   "metadata": {},
   "source": [
    "### Erosion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917f7e7c",
   "metadata": {},
   "source": [
    "A pixel in the original image (either 1 or 0) will be considered 1 only if all the pixels under the kernel is 1, otherwise it is eroded (made to zero).\n",
    "\n",
    "So what happens is that, all the pixels near boundary will be discarded depending upon the size of kernel. So the thickness or size of the foreground object decreases or simply white region decreases in the image.\n",
    "\n",
    "It is useful for removing small white noises (as we have seen in colorspace chapter), detach two connected objects etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8426b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"img/op.png\",0)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion = cv2.erode(img,kernel,iterations = 1)\n",
    "\n",
    "cv2.imshow(\"Erosion\",erosion)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e0c0ee",
   "metadata": {},
   "source": [
    "### Dilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c25220",
   "metadata": {},
   "source": [
    "It is just opposite of erosion. Here, a pixel element is ‘1’ if atleast one pixel under the kernel is ‘1’. So it increases the white region in the image or size of foreground object increases.\n",
    "\n",
    "Normally, in cases like noise removal, erosion is followed by dilation. Because, erosion removes white noises, but it also shrinks our object. So we dilate it. Since noise is gone, they won’t come back, but our object area increases. It is also useful in joining broken parts of an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0ee626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('img/op.png',0)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "dilation = cv2.dilate(img,kernel,iterations = 1)\n",
    "\n",
    "cv2.imshow('Dilation', dilation)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232ded5e",
   "metadata": {},
   "source": [
    "### Opening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ccb9d2",
   "metadata": {},
   "source": [
    "Opening is just another name of erosion followed by dilation. It is useful in removing noise, as we explained above. Here we use the function, cv2.morphologyEx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9abdab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('img/op.png',0)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('Opening', opening)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43c05d4",
   "metadata": {},
   "source": [
    "### Closing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d780b",
   "metadata": {},
   "source": [
    "Closing is reverse of Opening, Dilation followed by Erosion. It is useful in closing small holes inside the foreground objects, or small black points on the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "576fb08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('img/op.png',0)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "cv2.imshow('Closing', closing)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75c6c7d",
   "metadata": {},
   "source": [
    "### Morphological Gradient\n",
    "\n",
    "It is the difference between dilation and erosion of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32af5313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('img/op.png',0)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "\n",
    "cv2.imshow('gradient', gradient)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d91481",
   "metadata": {},
   "source": [
    "## Contours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed35a21d",
   "metadata": {},
   "source": [
    "Contours can be explained simply as a curve joining all the continuous points (along the boundary), having same color or intensity. The contours are a useful tool for shape analysis and object detection and recognition.\n",
    "\n",
    "For better accuracy, use binary images. So before finding contours, apply threshold or canny edge detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c66398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "im = cv2.imread('img/actress.jpg')\n",
    "imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "ret,thresh = cv2.threshold(imgray,127,255,0)\n",
    "contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cv2.imshow('Canny Edges After Contouring', thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7b712a",
   "metadata": {},
   "source": [
    "Three arguments in cv2.findContours() function,\n",
    "\n",
    "first one is source image,\n",
    "second is contour retrieval mode,\n",
    "third is contour approximation method.\n",
    "It outputs the image, contours and hierarchy.\n",
    "\n",
    "contours is a Python list of all the contours in the image. Each individual contour is a Numpy array of (x,y) coordinates of boundary points of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1489f26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 826\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "im = cv2.imread('img/actress.jpg')\n",
    "imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "ret,thresh = cv2.threshold(imgray,127,255,0)\n",
    "contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "print(\"Number of Contours found = \" + str(len(contours)))\n",
    "\n",
    "\n",
    "img = cv2.drawContours(img, contours, -1, (0,255,0), 3)\n",
    "cv2.drawContours(im, contours, -1, (0,255,0), 3)\n",
    "\n",
    "cv2.imshow('Contours', im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277f59af",
   "metadata": {},
   "source": [
    "Let's Draw the 255th counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "614cc12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "im = cv2.imread('img/actress.jpg')\n",
    "imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "ret,thresh = cv2.threshold(imgray,127,255,0)\n",
    "contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cnt = contours[600]\n",
    "img = cv2.drawContours(im, [cnt], 0, (0,255,0), 3)\n",
    "\n",
    "cv2.imshow('Contours', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc97488b",
   "metadata": {},
   "source": [
    "Using cv2.CHAIN_APPROX_NONE stores all the boundary points. But we don't necessarily need all bounding points. If the points form a straight line, we only need the start and ending points of that line.\n",
    "\n",
    "Using cv2.CHAIN_APPROX_SIMPLE instead only provides these start and end points of bounding contours, thus resulting in much more efficent storage of contour information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
