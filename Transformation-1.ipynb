{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c61a7c11",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a7eff9",
   "metadata": {},
   "source": [
    "### Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "919419b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"img/actress.jpg\")\n",
    "res = cv2.resize(img,None,fx=2,fy = 2,interpolation=cv2.INTER_CUBIC)\n",
    "cv2.imshow(\"Scaling\",res)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9302d32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 1000, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c133b6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height,width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32799022",
   "metadata": {},
   "outputs": [],
   "source": [
    "height,width = img.shape[:2]\n",
    "res = cv2.resize(img,(2*width,2*height),interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow(\"Scaling \",res)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa1b860",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a2b3d",
   "metadata": {},
   "source": [
    "Translation is the shifting of objectâ€™s location. If you know the shift in (x,y) direction, let it be (tx,ty), you can create the transformation matrix M as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036dec14",
   "metadata": {},
   "source": [
    "![title](img/tra.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521e063e",
   "metadata": {},
   "source": [
    "We can take make it into a Numpy array of type np.float32 and pass it into cv2.warpAffine() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf0c13ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"img/actress.jpg\",0)\n",
    "rows,cols = img.shape\n",
    "\n",
    "M = np.float32([[1,0,100],[0,1,100]])\n",
    "dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "cv2.imshow(\"img\",dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165f19b6",
   "metadata": {},
   "source": [
    "### Rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447a491d",
   "metadata": {},
   "source": [
    "Rotation of an image for an angle theta is achieved by the transformation matrix of the for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4eb645",
   "metadata": {},
   "source": [
    "![title](img/rot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bce28f",
   "metadata": {},
   "source": [
    "But OpenCV provides scaled rotation with adjustable center of rotation so that we can rotate at any location we prefer. Modified transformation matrix is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb89487",
   "metadata": {},
   "source": [
    "![title](img/rot1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b81341",
   "metadata": {},
   "source": [
    "where:\n",
    "    \n",
    "![title](img/rot2.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bde36ff",
   "metadata": {},
   "source": [
    "To find this transformation matrix, OpenCV provides a function, *cv2.getRotationMatrix2D*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a82c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"img/actress.jpg\")\n",
    "height,width = image.shape[:2]\n",
    "\n",
    "# Divide by two to rotate the image around its centre\n",
    "rotation_matrix = cv2.getRotationMatrix2D((width/2,height/2),90,0.5)\n",
    "rotated_image = cv2.warpAffine(image,rotation_matrix,(width,height))\n",
    "cv2.imshow(\"original Image\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"Roatated Image\",rotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af33f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 2\n",
    "\n",
    "img = cv2.imread(\"img/actress.jpg\")\n",
    "\n",
    "rotated_image = cv2.transpose(img)\n",
    "\n",
    "cv2.imshow(\"rotated Image\",rotated_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a41107e",
   "metadata": {},
   "source": [
    "### Horizontal Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb3cf1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped = cv2.flip(img,1)\n",
    "cv2.imshow(\"Horizontal Flip\",flipped)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181982f3",
   "metadata": {},
   "source": [
    "### Vertical Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2e5cff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped = cv2.flip(img,0)\n",
    "cv2.imshow(\"Horizontal Flip\",flipped)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed849f4a",
   "metadata": {},
   "source": [
    "### Affine Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ded089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = cv2.imread(\"img/actress.jpg\")\n",
    "rows,cols,ch = image.shape\n",
    "\n",
    "cv2.imshow(\"original\",image)\n",
    "cv2.waitKey()\n",
    "\n",
    "# coordinates of tghe 4 corners of the original image\n",
    "point_A = np.float32([[320,15],[700,215],[85,610]])\n",
    "\n",
    "# Coordinates of the 4 cornors of the desired output\n",
    "# we use a ratio of an A4 paper 1:1.41\n",
    "\n",
    "points_B = np.float32([[0,0],[500,0],[0,700]])\n",
    "\n",
    "# use two sets of four points to compute\n",
    "# the prespective transformation matrix, M\n",
    "\n",
    "M = cv2.getAffineTransform(point_A,points_B)\n",
    "\n",
    "warped = cv2.warpAffine(image,M,(cols,rows))\n",
    "\n",
    "cv2.imshow(\"warpPerspective\",warped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d57e9e4",
   "metadata": {},
   "source": [
    "### Perspective Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654f8bc6",
   "metadata": {},
   "source": [
    "For perspective transformation, we need a 3x3 transformation matrix. Straight lines will remain straight even after the transformation.\n",
    "\n",
    "To find this transformation matrix, we need 4 points on the input image and corresponding points on the output image.\n",
    "\n",
    "Among these 4 points, 3 of them should not be collinear.\n",
    "\n",
    "Then transformation matrix can be found by the function cv2.getPerspectiveTransform.\n",
    "\n",
    "Then apply cv2.warpPerspective with this 3x3 transformation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87161ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = cv2.imread('img/actress.jpg')\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Cordinates of the 4 corners of the original image\n",
    "points_A = np.float32([[320,15], [700,215], [85,610], [530,780]])\n",
    "\n",
    "# Cordinates of the 4 corners of the desired output\n",
    "# We use a ratio of an A4 Paper 1 : 1.41\n",
    "points_B = np.float32([[0,0], [420,0], [0,594], [420,594]])\n",
    " \n",
    "# Use the two sets of four points to compute \n",
    "# the Perspective Transformation matrix, M    \n",
    "M = cv2.getPerspectiveTransform(points_A, points_B)\n",
    " \n",
    "warped = cv2.warpPerspective(image, M, (420,594))\n",
    " \n",
    "cv2.imshow('warpPerspective', warped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e51913",
   "metadata": {},
   "source": [
    "# Smoothing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d960df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
